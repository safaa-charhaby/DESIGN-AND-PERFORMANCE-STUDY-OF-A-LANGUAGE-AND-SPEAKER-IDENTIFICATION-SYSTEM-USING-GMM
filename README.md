Here is the complete, raw Markdown code. You can copy everything inside the box below and paste it directly into your README.md file.

code
Markdown
download
content_copy
expand_less
<div align="center">

# ğŸ™ï¸ GMM-Based Language & Speaker Identification System
**Design, Implementation, and Performance Evaluation**

[![Python](https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python)](https://www.python.org/)
[![Machine Learning](https://img.shields.io/badge/ML-GMM--EM-orange?style=for-the-badge)](https://scikit-learn.org/)
[![Status](https://img.shields.io/badge/Project-Academic-success?style=for-the-badge)](https://github.com/)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](https://opensource.org/licenses/MIT)

**ğŸ“… Academic Year: 2025â€“2026**  
**ğŸ‘¨â€ğŸ« Supervisor: Prof. Jamal Kharroubi**

---

[**Overview**](#-overview) â€¢ [**Architecture**](#-system-architecture) â€¢ [**Performance**](#-performance-evaluation) â€¢ [**Setup**](#-installation--setup) â€¢ [**Structure**](#-project-structure)

</div>

---

## ğŸ“Œ Overview

This project presents a robust system for **Language Identification (LID)** and **Speaker Identification/Verification (SID)**. By utilizing **Gaussian Mixture Models (GMM)** and **MFCC** acoustic features, the system achieves high-accuracy recognition and provides a full pipeline from audio signal to translated speech.

### ğŸ¯ Core Capabilities
*   ğŸŒ **Language ID:** Detects 5 languages (French, English, Dutch, Darija, Japanese).
*   ğŸ§‘ **Speaker ID:** Identifies and verifies specific individual voices.
*   ğŸ“ **Transcription:** Converts speech to text in real-time.
*   ğŸŒ **Translation:** Translates recognized text to target languages.
*   ğŸ”Š **Synthesis:** Generates synthesized speech (TTS) for the output.

---

## ğŸ§  System Architecture

The system implements a statistical pattern recognition pipeline:

1.  **Preprocessing:** Hybrid Silence Removal (K-Means + GMM + Energy Thresholding).
2.  **Feature Extraction:** MFCC (Mel-Frequency Cepstral Coefficients).
3.  **Modeling:** Statistical modeling using GMM with Expectation-Maximization (EM).
4.  **Selection:** Model optimization via **Bayesian Information Criterion (BIC)**.

```mermaid
graph TD
    A[Audio Input] --> B[Hybrid Silence Removal]
    B --> C[MFCC Extraction]
    C --> D[GMM/EM Training]
    D --> E{Decision Engine}
    E --> F[Language Classification]
    E --> G[Speaker Verification]
ğŸ“Š Performance Evaluation

We conducted rigorous testing across different Gaussian components and test segment lengths.

ğŸ§ª Key Findings

Best Model: GMM with 256 Gaussians achieved the highest resolution.

Verification: Achieved an Equal Error Rate (EER) of 5.4%.

Reliability: 94.6% accuracy for speaker verification with 10s test segments.

ğŸ“ˆ Comparison Table
Parameter	Optimal Value	Impact
Gaussian Components	32 (LID) / 256 (SID)	Balances precision vs. speed
Training Duration	60 - 120 Seconds	Essential for model convergence
Test Segment	10 Seconds	Minimum for stable log-likelihood
ğŸ› ï¸ Installation & Setup
1. Clone & Environment
code
Bash
download
content_copy
expand_less
git clone https://github.com/your-username/GMM-Speech-ID.git
cd GMM-Speech-ID
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
2. Dependencies
code
Bash
download
content_copy
expand_less
pip install numpy librosa scikit-learn speech_recognition pyttsx3 gTTS matplotlib pandas
3. Run the Application
code
Bash
download
content_copy
expand_less
python App.py
ğŸ“ Project Structure
code
Text
download
content_copy
expand_less
.
â”œâ”€â”€ All_Gaussians/              # Trained models across different scales
â”œâ”€â”€ trained_models/             # Production-ready BIC-selected models
â”œâ”€â”€ data/                       # Dataset (Train/Test)
â”œâ”€â”€ notebooks/                  # Analysis and Plotting scripts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ silence_removal.py      # Hybrid thresholding logic
â”‚   â”œâ”€â”€ features.py             # MFCC extraction scripts
â”‚   â””â”€â”€ classification.py       # GMM inference logic
â”œâ”€â”€ App.py                      # GUI Application (Tkinter/PyQt)
â””â”€â”€ README.md
âš™ï¸ Technical Highlights
ğŸ”‡ Hybrid Silence Removal

Unlike standard thresholding, our system uses a Hybrid Method combining K-Means and Energy analysis. This ensures that:

Speech integrity is preserved.

Background noise is effectively suppressed.

Word truncation is minimized.

ğŸ§® Model Selection (BIC)

We don't just pick a random number of Gaussians. The system calculates the Bayesian Information Criterion (BIC) for multiple models and automatically selects the one that minimizes information loss while avoiding overfitting.

âœ… Conclusion

This project demonstrates that GMM-MFCC architectures remains highly effective for speech tasks. The system is efficient, scalable, and accurate, providing a solid foundation for real-world biometric and linguistic applications.

<div align="center">


Developed for the 2025â€“2026 Academic Term.
If you find this research helpful, please consider giving it a â­!

</div>
```
