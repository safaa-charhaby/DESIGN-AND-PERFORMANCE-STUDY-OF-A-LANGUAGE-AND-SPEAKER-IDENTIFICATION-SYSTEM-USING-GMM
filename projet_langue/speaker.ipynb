{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "244ce34f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69499504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import python_speech_features as psf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f24559",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "SPEAKERS_ROOT = \"./data/speakers/\"  # Path to the folder containing subfolders for each friend\n",
    "MODELS_DIR = \"trained_models_speakers/\" # New folder for speaker models\n",
    "\n",
    "if not os.path.exists(MODELS_DIR): os.makedirs(MODELS_DIR)\n",
    "\n",
    "# MFCC Parameters\n",
    "NUM_CEP = 13\n",
    "WIN_FUNC = np.hamming\n",
    "N_COMPONENTS_LIST = [4, 8, 16, 32, 64, 128, 256, 512]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705387e3",
   "metadata": {},
   "source": [
    "## File gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea6f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. FILE GATHERING (The Logic Update)\n",
    "# ==========================================\n",
    "def get_speaker_train_files(speaker_path):\n",
    "    \"\"\"\n",
    "    Goes into Friend folder -> Any Language Folder -> 'train' folder\n",
    "    And collects all audio files.\n",
    "    \"\"\"\n",
    "    # Pattern: data/speakers/Friend1/*/train/*.flac (or .wav)\n",
    "    # The '*' matches any language folder name\n",
    "    wav_files = glob.glob(os.path.join(speaker_path, \"*\", \"train\", \"*.wav\"))\n",
    "    flac_files = glob.glob(os.path.join(speaker_path, \"*\", \"train\", \"*.flac\"))\n",
    "\n",
    "    return wav_files + flac_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493bcbc",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e70f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. FEATURE EXTRACTION FUNCTION\n",
    "# ==========================================\n",
    "def extract_features_from_files(files):\n",
    "    if not files:\n",
    "        return None\n",
    "\n",
    "    all_features = []\n",
    "\n",
    "    for file_path in tqdm(files, leave=False):\n",
    "        try:\n",
    "            signal, sr = librosa.load(file_path, sr=None)\n",
    "            if len(signal.shape) > 1: signal = signal[0]\n",
    "\n",
    "            # MFCC\n",
    "            n_fft = 1024 if sr <= 16000 else 2048\n",
    "            mfccs = psf.mfcc(signal, sr, numcep=NUM_CEP, nfft=n_fft, winfunc=WIN_FUNC, appendEnergy=False)\n",
    "            if len(mfccs) < 10: continue\n",
    "\n",
    "            # Hybrid Silence Removal\n",
    "            energies = np.sum(np.square(mfccs), axis=1).reshape(-1, 1)\n",
    "\n",
    "            # Fast Init\n",
    "            kmeans = KMeans(n_clusters=2, n_init='auto', random_state=0).fit(energies)\n",
    "            gmm_sil = GaussianMixture(n_components=2, random_state=42).fit(energies)\n",
    "\n",
    "            threshold = (np.min(gmm_sil.means_) + np.min(kmeans.cluster_centers_)) / 2\n",
    "            is_speech = (energies > threshold).flatten()\n",
    "\n",
    "            clean_mfcc = mfccs[is_speech]\n",
    "            if len(clean_mfcc) < 10: continue\n",
    "\n",
    "            # Deltas\n",
    "            deltas = psf.delta(clean_mfcc, 2)\n",
    "            features = np.hstack((clean_mfcc, deltas))\n",
    "            all_features.append(features)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {os.path.basename(file_path)}: {e}\")\n",
    "\n",
    "    if all_features:\n",
    "        return np.vstack(all_features)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe95d29",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9459b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. TRAINING LOOP\n",
    "# ==========================================\n",
    "speaker_results = {}\n",
    "\n",
    "# Get list of speaker folders\n",
    "speakers = [d for d in os.listdir(SPEAKERS_ROOT) if os.path.isdir(os.path.join(SPEAKERS_ROOT, d))]\n",
    "\n",
    "print(f\"Found {len(speakers)} speakers: {speakers}\")\n",
    "\n",
    "for speaker in speakers:\n",
    "    speaker_path = os.path.join(SPEAKERS_ROOT, speaker)\n",
    "    print(f\"\\n--- Processing Speaker: {speaker} ---\")\n",
    "\n",
    "    # 1. Gather all 'train' files from all languages\n",
    "    train_files = get_speaker_train_files(speaker_path)\n",
    "    print(f\" -> Found {len(train_files)} training files (across all languages).\")\n",
    "\n",
    "    # 2. Extract Features\n",
    "    features = extract_features_from_files(train_files)\n",
    "    if features is None:\n",
    "        print(\" -> Not enough audio data. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\" -> Total Frames: {len(features)}\")\n",
    "\n",
    "    # 3. Train GMMs & Study Complexity\n",
    "    bic_scores = []\n",
    "    models = {}\n",
    "\n",
    "    for n in N_COMPONENTS_LIST:\n",
    "        if len(features) < n * 2:\n",
    "            bic_scores.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        # print(f\"Training n={n}...\", end=\"\\r\")\n",
    "        gmm = GaussianMixture(n_components=n, covariance_type='diag', max_iter=100, random_state=42)\n",
    "        gmm.fit(features)\n",
    "\n",
    "        score = gmm.bic(features)\n",
    "        bic_scores.append(score)\n",
    "        models[n] = gmm\n",
    "\n",
    "    # 4. Select Best Model\n",
    "    valid_scores = [s for s in bic_scores if not np.isnan(s)]\n",
    "    valid_n = [N_COMPONENTS_LIST[i] for i, s in enumerate(bic_scores) if not np.isnan(s)]\n",
    "\n",
    "    best_idx = np.argmin(valid_scores)\n",
    "    best_n = valid_n[best_idx]\n",
    "    best_model = models[best_n]\n",
    "\n",
    "    # Store for plotting\n",
    "    speaker_results[speaker] = {\"n\": valid_n, \"bic\": valid_scores, \"best\": best_n}\n",
    "\n",
    "    # 5. Save\n",
    "    save_path = os.path.join(MODELS_DIR, f\"GMM_Speaker_{speaker}_best.joblib\")\n",
    "    joblib.dump(best_model, save_path)\n",
    "    print(f\" -> Saved Best Model (n={best_n}) to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ed745",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. PLOT BIC SCORES\n",
    "# ==========================================\n",
    "plt.figure(figsize=(10, 6))\n",
    "for spk, data in speaker_results.items():\n",
    "    plt.plot(data[\"n\"], data[\"bic\"], marker='o', label=f\"{spk} (Best: {data['best']})\")\n",
    "\n",
    "plt.title(\"Speaker Model Complexity Study (BIC)\")\n",
    "plt.xlabel(\"Number of Gaussians\")\n",
    "plt.ylabel(\"BIC Score (Lower is Better)\")\n",
    "plt.xscale('log')\n",
    "plt.xticks(N_COMPONENTS_LIST, labels=N_COMPONENTS_LIST)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
